{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating default and asset correlation with method of moments and maximum likelihood method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Python notebook, we reproduce the numerical results of chapter 6 \"Modelling and Estimating Default Correlation with the Asset Value Approach\" in Credit Risk Modeling using Excel and VBA, by Gunter Loffler and Peter Posch \n",
    "\n",
    "https://www.wiley.com/en-gb/Credit+Risk+Modeling+using+Excel+and+VBA%2C+2nd+Edition-p-9780470660928.\n",
    "\n",
    "Remarkably, the authors carried out the original work in excel! It is so much easier to implement the same algos in python. However, as the algos are numerically involved, we are not surprised to find our implementation also slow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main assuptions behind the original work: 1) All obligors share the same defaut and joint default probabilities as the other obligors in the same credit group, either Investment Grade or Specuative Grade. 2) There is no serial correlation in the time series of defaults, so defaults in any year are not affected by the defaults in a previous year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the mathematical derivations and formulae, please look at chapter 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from scipy.stats     import norm\n",
    "from scipy.optimize  import root\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize  import minimize\n",
    "from scipy.special   import comb\n",
    "from scipy.stats     import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read our data set, from the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  IGDefaults  SpeculativeGradeDefaults  IG_No  SpeculativeGrade_No\n",
      "0  1981           0                         2   1064                  321\n",
      "1  1982           2                        15   1093                  340\n",
      "    Year  IGDefaults  SpeculativeGradeDefaults  IG_No  SpeculativeGrade_No\n",
      "27  2008          14                        88   3398                 2528\n",
      "28  2009          11                       223   3445                 2415\n"
     ]
    }
   ],
   "source": [
    "DefaultData = pd.read_csv ('DefaultHistory.csv', index_col=False)\n",
    "print (DefaultData.head(2))\n",
    "print (DefaultData.tail(2))\n",
    "size = len(DefaultData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29 entries, 0 to 28\n",
      "Data columns (total 5 columns):\n",
      "Year                        29 non-null int64\n",
      "IGDefaults                  29 non-null int64\n",
      "SpeculativeGradeDefaults    29 non-null int64\n",
      "IG_No                       29 non-null int64\n",
      "SpeculativeGrade_No         29 non-null int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 1.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (DefaultData.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods of Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the average default rate for the Investment Grades and Speculative credit categories, $ p_{ig}$ and $p_{spec}$ by averaging their respective annual default rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultData['DefaultRateIG']     = DefaultData.IGDefaults              /DefaultData.IG_No\n",
    "DefaultData['DefaultRateSpec']   = DefaultData.SpeculativeGradeDefaults/DefaultData.SpeculativeGrade_No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageDefaultRateIG   = np.mean(DefaultData['DefaultRateIG'])\n",
    "AverageDefaultRateSpec = np.mean(DefaultData['DefaultRateSpec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011440217358502029\n",
      "0.04369411291593368\n"
     ]
    }
   ],
   "source": [
    "print(AverageDefaultRateIG)\n",
    "print(AverageDefaultRateSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint default rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now estimate the average joint default rates as we previously did for the default rates. \n",
    "\n",
    "We relate the number of observed joint (pair) defaults to the total number of possible joint (pair) defaults as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's indicate with $D_t$ the number of defaults in year $t$ and with $N_t$ the number of exposures at the beginning of year $t$\n",
    "\n",
    "The number of observed joint (pair) defaults is\n",
    "$$ {{D_t}\\choose 2} =  \\frac{D_t(D_t -1)}{2} $$\n",
    "$$ $$\n",
    "The total number of possible joint (pair) defaults is\n",
    "$$ {{N_t}\\choose 2} =  \\frac{N_t(N_t -1)}{2} $$\n",
    "$$ $$\n",
    "The joint default rate for year $t$ is\n",
    "$$ p_{joint, t}=  \\frac{D_t(D_t -1)}{N_t(N_t -1)} $$\n",
    "$$ $$\n",
    "and the average joint default rate for all $t's$ is \n",
    "$$p_{joint} = \\frac{1}{T}\\sum_{t=1}^T p_{joint, t}=\\frac{1}{T}\\sum_{t=1}^T \\frac{D_t(D_t -1)}{N_t(N_t -1)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultData['Joint_Def_ProbIG']     = DefaultData.IGDefaults * (DefaultData.IGDefaults -1) \\\n",
    "/(DefaultData.IG_No*(DefaultData.IG_No -1))\n",
    "\n",
    "DefaultData['Joint_Def_ProbSpec']   = DefaultData.SpeculativeGradeDefaults *(DefaultData.SpeculativeGradeDefaults - 1) \\\n",
    "/(DefaultData.SpeculativeGrade_No*(DefaultData.SpeculativeGrade_No-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2e-06\n",
      "0.002624\n"
     ]
    }
   ],
   "source": [
    "JointDefProbIG   = np.mean(DefaultData['Joint_Def_ProbIG'])\n",
    "JointDefProbSpec = np.mean(DefaultData['Joint_Def_ProbSpec'])\n",
    "\n",
    "print(np.round(JointDefProbIG,6))\n",
    "print(np.round(JointDefProbSpec,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default correlation is specified by the individual and joint default probabilities. So using the average default and joint default probabilities, we calculate the default correlation as\n",
    "\n",
    "$$\\rho_{i,j}= \\frac{p_{i,j}-p_ip_j}{\\sqrt{p_i(1-p_j)p_j(1-p_i)}} $$\n",
    "\n",
    "Again, as stated earlier, we assume all obligors in the same category, share the same default and joint default probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultCorrIG   = (JointDefProbIG - AverageDefaultRateIG*AverageDefaultRateIG)\\\n",
    "/(np.sqrt(AverageDefaultRateIG*(1-AverageDefaultRateIG)*AverageDefaultRateIG*(1-AverageDefaultRateIG)))\n",
    "\n",
    "DefaultCorrSpec = (JointDefProbSpec - AverageDefaultRateSpec*AverageDefaultRateSpec)\\\n",
    "/(np.sqrt(AverageDefaultRateSpec*(1-AverageDefaultRateSpec)*AverageDefaultRateSpec*(1-AverageDefaultRateSpec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The asset value model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of imposing the default correlation structure \"directly\" from the historic default data, more conveniently defaults can represented as function of continuous \"random\" variables and then a joint default structure is imposed on these variables. \n",
    "\n",
    "These variables are often referred as latent variables and are interpreted as the firm's asset value. When the asset value $A_i$ drops below a critical value $d_i$ (called default threshod), default is triggered.\n",
    "\n",
    "The default indicator for the obligor $i$ can be represented as\n",
    "$$Default_i = 1 \\, ,if \\, A_i <= d_i$$\n",
    "\n",
    "whereas the no default indicator is \n",
    "\n",
    "$$No \\, default_i = 0 \\, ,if \\, A_i > d_i$$\n",
    "\n",
    "The joint default probability is instead written as \n",
    "$$Prob(A_i <= d_i \\, , A_j <= d_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing, the asset value $A_i$ depends on the common factor $Z$, which is common to all obligors, on the idiosyncratic factor $\\epsilon_i$ and on the factor sensitivity $w_i$\n",
    "\n",
    "$$A_{i} = w_iZ+\\sqrt{1-w_i^2}\\epsilon_i$$\n",
    "\n",
    "The asset correlation between $i$ and $j$ is completely determined by their factor sensitivities $w_i$ and $w_j$ and simplifies to\n",
    "\n",
    "$$\\rho_{i,j}^{asset}= w_iw_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default probability is given by\n",
    "$$P[A_i<=d_i] = p_i = \\Phi(d_i)$$\n",
    "\n",
    "and the joint default probability is given by\n",
    "$$P[A_i<=d_i,A_j<=d_j ] = p_{i,j} = \\Phi_{2}(d_i, d_j,\\rho_{i,j}^{asset})$$\n",
    "\n",
    "where \n",
    "$\\Phi(d_i)$ is the cumulative standard normal distribution function and\n",
    "$$ $$\n",
    "$\\Phi_{2}(d_i, d_j,\\rho_{i,j}^{asset})$ is the bivariate standard normal distribution function with asset correlation $\\rho_{i,j}^{asset}$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a credit is allocated to one of the two credit categories (Investment Grades or Speculative), it will share the same default rate, joint defaut rate, critical value (or default threshold), default and asset correlation of all the other credits in the same category. It is a big assumption indeed!\n",
    "\n",
    "With those assumptions in mind it is easy to find the asset correlation, $ \\rho_{i,j}^{asset}$, that allows us to match the joint default rate as calculated earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce the following three functions to parametrize the asset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tetrachoric(x , y , rho): \n",
    "\n",
    "    FACCURACY = 0.0000000000001\n",
    "    MinStopK  = 20    \n",
    "    hx  = 1\n",
    "    hy  = 1\n",
    "    hx1 = 0\n",
    "    hy1 = 0\n",
    "    k   = 0\n",
    "    c   = rho\n",
    "    z   = c\n",
    "    s   = z\n",
    "    CheckPass = 0\n",
    "\n",
    "    while (CheckPass < MinStopK):\n",
    "        k   = k + 1\n",
    "        hx2 = hx1\n",
    "        hy2 = hy1\n",
    "        hx1 = hx\n",
    "        hy1 = hy\n",
    "        hx  = x * hx1 - (k - 1) * hx2\n",
    "        hy  = y * hy1 - (k - 1) * hy2\n",
    "        c   = c * rho / (k + 1)\n",
    "        z   = hx * hy * c\n",
    "        s   = s + z\n",
    "        if (abs(z / s) < FACCURACY):\n",
    "            CheckPass = CheckPass + 1\n",
    "        else:\n",
    "            CheckPass = 0\n",
    "        \n",
    "    return s\n",
    "\n",
    "def bivnor(x , y , rho):\n",
    "    biv = 0.0\n",
    "    if (rho == 0):\n",
    "        biv = norm.cdf(x) * norm.cdf(y)\n",
    "    else:\n",
    "        biv = norm.cdf(x) * norm.cdf(y) + norm.pdf(x) * norm.pdf(y) * tetrachoric(x, y, rho)\n",
    "    return biv\n",
    "\n",
    "def wrapperRoot(x, y, jointDefault):\n",
    "    def f(rho):\n",
    "        return bivnor(x,y,rho) - jointDefault\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default Triggers\n",
    "\n",
    "are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0500485880438437\n",
      "-1.7093387152616\n"
     ]
    }
   ],
   "source": [
    "x_inverseDRIG   = norm.ppf(AverageDefaultRateIG,   loc=0, scale=1)\n",
    "x_inverseDRSpec = norm.ppf(AverageDefaultRateSpec, loc=0, scale=1)\n",
    "print(x_inverseDRIG)\n",
    "print(x_inverseDRSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Default rate for the IG credit is 2.1991576201508045e-06\n",
      "Asset Correlation  for the IG credit is 0.04883917450262377\n"
     ]
    }
   ],
   "source": [
    "# Let's find now the asset correlation which matches the joint default rate for the IG credit group\n",
    "print(\"Joint Default rate for the IG credit is\", JointDefProbIG)\n",
    "ff  = wrapperRoot(x_inverseDRIG,x_inverseDRIG,JointDefProbIG)\n",
    "sol = root(ff,0.05)\n",
    "AssetCorrIG = sol.x[0]\n",
    "print(\"Asset Correlation  for the IG credit is\", AssetCorrIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1991576201508045e-06\n",
      "2.1991576201508045e-06\n"
     ]
    }
   ],
   "source": [
    "# so assuming an asset correlation of 0.0488, the joint default probability is the same as above\n",
    "print(bivnor(x_inverseDRIG,x_inverseDRIG,0.04883917450262377))\n",
    "print(JointDefProbIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same for the speculative credit category\n",
    "ff  = wrapperRoot(x_inverseDRSpec,x_inverseDRSpec,JointDefProbSpec)\n",
    "sol = root(ff,0.05)\n",
    "AssetCorrSpec = sol.x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let' print the moments so far calcuated, which we remind were estimated directly on the historic default data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Type      Default Prob       Joint Default Prob       Default Correlation\n",
      "IG                 0.0011            0.00000220                   0.00077917\n",
      "Speculative        0.0437            0.00262395                   0.017106\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:16} {1:18} {2:24} {3:8}\".format(\"Credit Type\", \"Default Prob\", \"Joint Default Prob\", \"Default Correlation\"))\n",
    "\n",
    "print('{0} {1:22.4f} {2:21.8f} {3:28.5}'.format (\"IG\",AverageDefaultRateIG, JointDefProbIG, DefaultCorrIG))\n",
    "print('{0} {1:13.4f} {2:21.8f} {3:26.5}'.format (\"Speculative\",AverageDefaultRateSpec, JointDefProbSpec, DefaultCorrSpec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas when using an asset model to describe a default, the moments are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Type      Default Threshold    Joint Default Prob     Asset Correlation\n",
      "IG                -3.0500                 0.00000220              0.048839\n",
      "Speculative       -1.7093                 0.00262395              0.074955\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:16} {1:20} {2:22} {3:8}\".format(\"Credit Type\", \"Default Threshold\", \"Joint Default Prob\", \"Asset Correlation\"))\n",
    "\n",
    "print('{0} {1:22.4f} {2:26.8f} {3:21.5}'.format (\"IG\",x_inverseDRIG, JointDefProbIG, AssetCorrIG))\n",
    "print('{0} {1:13.4f} {2:26.8f} {3:21.5}'.format (\"Speculative\",x_inverseDRSpec, JointDefProbSpec, AssetCorrSpec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Asset Correlation with Maximum Likelihood - One factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can apply the maximum likelihood method to parametrize an asset model. In a nutshell, with the MLM we determine the default probability and the factor sensitivity, such that the probability of observing the historical default rate is maximised.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, we write the default probability of obligor $i$ associated to a given realization of the factor $Z$ as\n",
    "\n",
    "$$p_i(Z) = P\\left[A_i<=\\Phi^{-1}(p_i)|Z\\right]$$\n",
    "$$ $$\n",
    "$$p_i(Z) =\\Phi{\\left(\\frac{\\Phi^{-1}(p_i) - w_iZ}{\\sqrt{1-w^2}}\\right)}$$\n",
    "\n",
    "Conditional on the realization of the factor $Z$, defaults are independent.\n",
    "If the conditional default probability is the same across all obligors at $p(Z)$, and defaults at time $t$ are independent from defaults at time $t-1$, then the total number of defaults $D$ follows a binomial distribution with success probabiity $p(Z)$ and $N$ trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the binomial formula $${{N}\\choose{k}} \\cdot p^kq^{N-k}$$\n",
    "\n",
    "leads to the following log likelihood function for the number of defaults for the group $k$ = $\\{$Investment and Speculative Grade$\\}$, in year $t=$\\{1,..,$T$}\n",
    "\n",
    "$$ln(L_k) = \\sum_{t=1}^T ln\\int_{-\\infty}^\\infty {{N_{kt}}\\choose{D_{kt}}} \\cdot p_k(Z)^{D_{kt}}(1-p_k(Z))^{N_{kt}-D_{kt}}d\\Phi(Z)$$\n",
    "\n",
    "The log likelihood function will be applied to the two credit groups indipendently as follows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the binomial expression, $p(Z)$ and log likelhood function in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pz(p,w,z):\n",
    "    num = norm.ppf(p)-np.multiply(w,z)\n",
    "    pG  = norm.cdf(np.divide(num,np.sqrt(1-w*w)))\n",
    "    return pG\n",
    "\n",
    "def CMFz(z, Rho, p, N, K):\n",
    "    pg  = Pz(p,Rho, z)    \n",
    "    f   = comb(N,K)*np.power(pg,K)*np.power(1-pg,N-K)\n",
    "    cmf = f        \n",
    "    return cmf\n",
    "\n",
    "def logL(Rho_p, T, nVec, kVec):\n",
    "    Rho  = Rho_p[0]\n",
    "    p    = Rho_p[1]    \n",
    "    L    = np.zeros(T)\n",
    "\n",
    "    for t in range(0,T):\n",
    "        ss = np.array([CMFz(s, Rho, p, nVec[t], kVec[t]) for s in x])\n",
    "        for i in range(0,size):            \n",
    "            L[t] =  np.dot(ss,y)\n",
    "    logL = -np.sum(np.log(L))\n",
    "    return logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.1\n",
    "x = [-5 + i * h for i in range(101)] \n",
    "y = np.array([norm.pdf(s)*h for s in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the array $y$ is indeed a probability density. It should sum to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999996"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sum(y),7) # close enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can replicate the log likelihood function value as it was reported in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the book the probability and factor sensitivity for the sector IG were below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp    = 0.00121497751624143\n",
    "wi    = 0.276457395273792\n",
    "Rho_p = (wi,pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8487256141381895\n"
     ]
    }
   ],
   "source": [
    "# for t = 1981, it agrees!\n",
    "print(logL(Rho_p, 1, np.array(DefaultData.IG_No), np.array(DefaultData.IGDefaults)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.27009497803652\n"
     ]
    }
   ],
   "source": [
    "# for for the full IG data set it agrees too!\n",
    "print(logL(Rho_p, 29, np.array(DefaultData.IG_No), np.array(DefaultData.IGDefaults)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can find the same probability and factor sensitivity for the sector IG by maximizing the log likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1       = np.array(DefaultData.IG_No)\n",
    "X2       = np.array(DefaultData.IGDefaults)\n",
    "theta    = np.ones(2)\n",
    "theta[0] = 0.20\n",
    "theta[1] = AverageDefaultRateIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 60.27009491039413\n",
      "     jac: array([0.00558771, 0.07108838])\n",
      " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
      "    nfev: 26\n",
      "     nit: 8\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.27644787, 0.00121494])\n"
     ]
    }
   ],
   "source": [
    "res_IG = minimize(logL, theta, args=(29,X1,X2), method='TNC',jac=None, options={'maxiter':50}) \n",
    "print (res_IG)\n",
    "# they are very close!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems with the \"scipy.special.comb\" for the Speculative credit group\n",
    "\n",
    "The function comb returns $\\infty$ when the number $k$ is too large. The problem was already highlighted by the authors who also provided an alternative algo, called sterling approximation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "740.0467215389326"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from math import pi, log, exp\n",
    "\n",
    "def lncombin(n, k):\n",
    "    res = 0\n",
    "    if(comb(n,k) == math.inf):\n",
    "        if (k == 0) :\n",
    "            res = 0\n",
    "        else:\n",
    "            lfn = (n + 0.5) * log(n) - n + 0.5 * log(2 * pi)\n",
    "            lfk = (k + 0.5) * log(k) - k + 0.5 * log(2 * pi)\n",
    "            lfnk = ((n - k) + 0.5) * log(n - k) - (n - k) + 0.5 * log(2 * pi)\n",
    "            res = lfn - lfk - lfnk    \n",
    "\n",
    "    else:\n",
    "        res = log(comb(n,k))\n",
    "    return res\n",
    "\n",
    "# test it!\n",
    "lncombin(2415,223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's rewrite the previous function where we use the sterling approximation.\n",
    "def CMFzSterling(z, Rho, p, N, K):\n",
    "    pg  = Pz(p,Rho, z)    \n",
    "    f   = lncombin(N,K) + log(pg)*K + log(1-pg)*(N-K)\n",
    "    cmf = exp(f)        \n",
    "    return cmf\n",
    "\n",
    "def logLSterling(Rho_p, T, nVec, kVec):\n",
    "    Rho  = Rho_p[0]\n",
    "    p    = Rho_p[1]    \n",
    "    L    = np.zeros(T)\n",
    "    for t in range(0,T):\n",
    "        ss = np.array([CMFzSterling(s, Rho, p, nVec[t], kVec[t]) for s in x])\n",
    "        for i in range(0,size):            \n",
    "            L[t] =  np.dot(ss,y)\n",
    "    logL = -np.sum(np.log(L))\n",
    "    return logL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run the MLM on the Speculative credit group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 132.24879725873734\n",
      "     jac: array([-0.00841567,  0.02413856])\n",
      " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
      "    nfev: 45\n",
      "     nit: 9\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.29139055, 0.04385974])\n"
     ]
    }
   ],
   "source": [
    "X1       = np.array(DefaultData.SpeculativeGrade_No)\n",
    "X2       = np.array(DefaultData.SpeculativeGradeDefaults)\n",
    "theta    = np.ones(2)\n",
    "theta[0] = 0.15\n",
    "theta[1] = AverageDefaultRateSpec\n",
    "res_Spec = minimize(logLSterling, theta, args=(29,X1,X2), method='TNC',jac=None, options={'maxiter':50}) \n",
    "print (res_Spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Asset Correlation with Maximum Likelihood - Two factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could run the MLM on all data we have available, IG and Speculative, in one go, and estimate the default probabilities and factor sensitivities for the two sectors. \n",
    "\n",
    "The joint probability of observing IG and Speculative grade defaulting is estimated for a given realization on $Z$, which is common to IG and Speculative credits. So we can still use the binomial formula, as once we know $Z$, we will be dealing with independent events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMFzSterling2Factors(z, Rho1, p1, Rho2, p2, N1, K1, N2, K2):\n",
    "    pg1  = Pz(p1,Rho1, z)\n",
    "    pg2  = Pz(p2,Rho2, z)\n",
    "    \n",
    "    f1   = lncombin(N1,K1) + log(pg1)*K1 + log(1-pg1)*(N1-K1)\n",
    "    f2   = lncombin(N2,K2) + log(pg2)*K2 + log(1-pg2)*(N2-K2)\n",
    "    cmf = exp(f1 + f2)        \n",
    "    return cmf\n",
    "\n",
    "def logLSterling2Factors(Rho_p, T, nVec1, kVec1, nVec2, kVec2):\n",
    "    Rho1  = Rho_p[0]\n",
    "    p1    = Rho_p[1]    \n",
    "    Rho2  = Rho_p[2]\n",
    "    p2    = Rho_p[3]    \n",
    "    L    = np.zeros(T)\n",
    "    \n",
    "    for t in range(0,T):\n",
    "        ss = np.array([CMFzSterling2Factors(s, Rho1, p1, Rho2, p2, nVec1[t], kVec1[t], nVec2[t], kVec2[t]) for s in x])\n",
    "        for i in range(0,size):            \n",
    "            L[t] =  np.dot(ss,y)\n",
    "    logL = -np.sum(np.log(L))\n",
    "    return logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 186.5334705044338\n",
      "     jac: array([-15.73734778,  69.67679553,  -0.11623342,  24.73203438])\n",
      " message: 'Max. number of function evaluations reached'\n",
      "    nfev: 50\n",
      "     nit: 10\n",
      "  status: 3\n",
      " success: False\n",
      "       x: array([0.20353734, 0.0012931 , 0.27907251, 0.04347081])\n"
     ]
    }
   ],
   "source": [
    "X1_IG = np.array(DefaultData.IG_No)\n",
    "X2_IG = np.array(DefaultData.IGDefaults)\n",
    "\n",
    "X1_Sp = np.array(DefaultData.SpeculativeGrade_No)\n",
    "X2_Sp = np.array(DefaultData.SpeculativeGradeDefaults)\n",
    "\n",
    "theta  = np.ones(4)\n",
    "theta[0]= 0.20\n",
    "theta[1]= AverageDefaultRateIG\n",
    "theta[2]= 0.15\n",
    "theta[3] = AverageDefaultRateSpec\n",
    "\n",
    "res_2Fact = minimize(logLSterling2Factors, theta, args=(29,X1_IG,X2_IG, X1_Sp,X2_Sp), \\\n",
    "                     method='TNC',jac=None, options={'maxiter':50}) \n",
    "print (res_2Fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's report the MLM values so far calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Method of Moments     Maximum Likelihood 1F   Maximum Likelihood 2F's\n",
      "IG p                0.0011                    0.00121               0.00129\n",
      "IG rho              0.0488                    0.07642               0.04143\n",
      "Spec p              0.0437                    0.04386               0.04347\n",
      "Spec rho            0.0750                    0.08491               0.07788\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:13} {1:21} {2:23} {3:22}\".format(\" \", \"Method of Moments\", \"Maximum Likelihood 1F\", \"Maximum Likelihood 2F's\"))\n",
    "\n",
    "print('{0} {1:21.4f} {2:26.5f} {3:21.5f}'.format(\"IG p\",    AverageDefaultRateIG,  res_IG.x[1],      res_2Fact.x[1]))\n",
    "print('{0} {1:19.4f} {2:26.5f} {3:21.5f}'.format(\"IG rho\",  AssetCorrIG,           res_IG.x[0]**2,   res_2Fact.x[0]**2))\n",
    "print('{0} {1:19.4f} {2:26.5f} {3:21.5f}'.format(\"Spec p\",  AverageDefaultRateSpec,res_Spec.x[1],    res_2Fact.x[3]))\n",
    "print('{0} {1:17.4f} {2:26.5f} {3:21.5f}'.format(\"Spec rho\",AssetCorrSpec,         res_Spec.x[0]**2, res_2Fact.x[2]**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a benefit when using a MLM with 2 factors vs MLM with 1 factor: MLM-2F's $p'$s and rho's are much closer to the respective values calculated with Methods of Moments    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, we compare our runs against those reported in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Book MLM 1F               Book MLM 2F             MLM 1F                 MLM 2F                \n",
      "IG p               0.00121                 0.0013745               0.0012149              0.0012931\n",
      "IG rho             0.07643                 0.07119218              0.076423               0.041427\n",
      "Spec p              NA                     0.044464                0.04386                0.04347\n",
      "Spec rho            NA                     0.10700914              0.084908               0.077881\n",
      "MLM Value-IG      60.2701                185.7244                 60.2701               186.53\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:14} {1:25} {2:23} {3:22} {4:22}\".format(\" \", \"Book MLM 1F\",\"Book MLM 2F\", \"MLM 1F\", \"MLM 2F\"))\n",
    "\n",
    "print('{0} {1:21.5f} {2:25.5}  {3:22.5} {4:22.5}'.format (\"IG p\",0.00121498,0.001374488, res_IG.x[1],res_2Fact.x[1]))\n",
    "print('{0} {1:19.5f} {2:26.8f} {3:21.5} {4:22.5}'.format (\"IG rho\",  0.076428691, 0.071192177, res_IG.x[0]**2,res_2Fact.x[0]**2))\n",
    "print('{0:19} {1:6}  {2:23.6f} {3:22.5f}{4:23.5f}'.format (\"Spec p\",  \"NA\", 0.044464189, res_Spec.x[1], res_2Fact.x[3]))\n",
    "print('{0:19} {1:6}  {2:25.8f} {3:21.5} {4:22.5}'.format (\"Spec rho\",\"NA\", 0.107009136, res_Spec.x[0]**2,res_2Fact.x[2]**2))\n",
    "print('{0:17} {1:6.4f} {2:23.4f} {3:23.4f} {4:20.5}'.format (\"MLM Value-IG\",60.2700527, 185.7244, res_IG.fun, res_2Fact.fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate with scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the MLM to find model coefficients takes a very long time. The algo is numerically intense. \n",
    "\n",
    "Do we save calculation time if we replace, in in the function logL(), the numerical solution of the integral\n",
    "\n",
    "$$ln(L_k) = \\sum_{t=1}^T ln\\int_{-\\infty}^\\infty {{N_{kt}}\\choose{D_{kt}}} \\cdot p_k(Z)^{D_{kt}}(1-p_k(Z))^{N_{kt}-D_{kt}}d\\Phi(z)$$\n",
    "\n",
    "with the quad object from scipy.integrate ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we modify CMFz and logL as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMFzquad(z, Rho, p, N, K):\n",
    "    pg  = Pz(p,Rho, z)    \n",
    "    f   = comb(N,K)*np.power(pg,K)*np.power(1-pg,N-K)\n",
    "    cmf = f*norm.pdf(z)        \n",
    "    return cmf\n",
    "\n",
    "def logLquad(Rho_p, T, nVec, kVec):\n",
    "    Rho  = Rho_p[0]\n",
    "    p    = Rho_p[1]    \n",
    "    L    = np.zeros(T)    \n",
    "    \n",
    "    for t in range(0,T):\n",
    "        fCMF = lambda s, Rho, p, nX, kX: CMFzquad(s, Rho,p,nX,kX)\n",
    "        L[t],err = quad(fCMF,-5,5, args=(Rho, p, nVec[t], kVec[t]))\n",
    "    logL = -np.sum(np.log(L))\n",
    "    return logL          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the algo on the IG data for year, $t$ = 1981, and see if it it agrees with our previous results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8487257730543333\n",
      "0.8487256141381895\n"
     ]
    }
   ],
   "source": [
    "# and it does\n",
    "print(logLquad(Rho_p, 1, np.array(DefaultData.IG_No), np.array(DefaultData.IGDefaults)))\n",
    "print(logL(Rho_p, 1, np.array(DefaultData.IG_No), np.array(DefaultData.IGDefaults)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for the full IG data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.2700972395946\n",
      "60.27009497803652\n"
     ]
    }
   ],
   "source": [
    "# It agrees too!\n",
    "print(logLquad(Rho_p, 29, np.array(DefaultData.IG_No), np.array(DefaultData.IGDefaults)))\n",
    "print(logL(Rho_p, 29, np.array(DefaultData.IG_No), np.array(DefaultData.IGDefaults)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's find the ML parameters for the IG dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 60.27009711920736\n",
      "     jac: array([0.00163638, 0.00667342])\n",
      " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
      "    nfev: 27\n",
      "     nit: 8\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.27643282, 0.00121492])\n"
     ]
    }
   ],
   "source": [
    "X1       = np.array(DefaultData.IG_No)\n",
    "X2       = np.array(DefaultData.IGDefaults)\n",
    "theta    = np.ones(2)\n",
    "theta[0] = 0.20\n",
    "theta[1] = AverageDefaultRateIG\n",
    "\n",
    "res_IG_quad = minimize(logLquad, theta, args=(29,X1,X2), method='TNC',jac=None, options={'maxiter':50}) \n",
    "print(res_IG_quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and see how it compares with our previous results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27643282 0.00121492]\n",
      "[0.27644787 0.00121494]\n"
     ]
    }
   ],
   "source": [
    "# Parameter vaues are very close!!\n",
    "print (res_IG_quad.x)\n",
    "print (res_IG.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.27009711920736\n",
      "60.27009491039413\n"
     ]
    }
   ],
   "source": [
    "# and so is the MLM value!!\n",
    "print (res_IG_quad.fun)\n",
    "print (res_IG.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there any time saving?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 s ± 32.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (logLquad(Rho_p, 29, np.array(DefaultData.IG_No), np.array(DefaultData.IGDefaults)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765 ms ± 57.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (logL(Rho_p, 29, np.array(DefaultData.IG_No), np.array(DefaultData.IGDefaults)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that surprisingly, scipy.integrate.quad is slower!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following two lines, we also tested the calculation time on the minimize algo with and without quad. The testing is very slow and it does take sometime to complete, so do not run it unless you really need it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 40s ± 3.83 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit minimize(logLquad, theta, args=(29,X1,X2), method='TNC',jac=None, options={'maxiter':20}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 89.43 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "13min 27s ± 30min 30s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit minimize(logL, theta, args=(29,X1,X2), method='TNC',jac=None, options={'maxiter':20}) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
